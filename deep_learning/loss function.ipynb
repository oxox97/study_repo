{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfa8f4d",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262718f",
   "metadata": {},
   "source": [
    "### 1. 개념\n",
    "- 모델이 정답과 얼마나 다른지(오차)를 측정하는 함수\n",
    "- 딥러닝 학습의 핵심 목표는 이 Loss를 최고화하는 것\n",
    "\n",
    "### 2. 주요 손실 함수와 수식\n",
    "\n",
    "| 함수 | 수식 | 주요 특징 | 사용 상황 | 장점 | 단점 |\n",
    "|------|------|-----------|-----------|------|------|\n",
    "| **MSE** (Mean Squared Error) | $MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | 예측과 실제값의 제곱 오차 | 회귀 문제 | 계산이 직관적이고 미분이 간단함 | 이상치에 민감함 |\n",
    "| **MAE** (Mean Absolute Error) | $MAE = (abs) | 예측과 실제값의 절댓값 오차 | 회귀 문제 | 이상치에 덜 민감함 | 절댓값 함수는 미분 불연속 |\n",
    "| **Cross Entropy** | $CE = - \\sum y_i \\log(\\hat{y}_i)$ | 정답 확률이 높을수록 loss 감소 | 다중 분류 | 확률 기반 분류에 적합 | 확률이 0에 가까우면 수치 불안정 |\n",
    "| **BCE** (Binary Cross Entropy) | $BCE = - [y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]$ | 이진 분류 전용 Cross Entropy | 이진 분류 | 확률 출력 해석 가능 | 정반대 예측 시 큰 페널티 |\n",
    "| **KL Divergence** | $D_{KL}(P \\| Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)}$ | 두 확률 분포 간 차이 | VAE, 분포 비교 | 분포 자체를 학습 가능 | $Q(x) = 0$이면 발산 위험 |\n",
    "\n",
    "### 3. 정보 이론\n",
    "- Entropy : 정답 분포 자체의 정보량 (불확실할 때 정보량이 많음)\n",
    "    - 평균 놀람도(정보량)라고도 불리며, \"확률이 낮은 사건일수록, 일어났을 때 놀람이 큼\"을 기반으로 함\n",
    "    - 정보량 (surprise): $I(x) = -\\log P(x)$ (확률에 반비례)\n",
    "    - 엔트로피 (평균 정보량): $H(P) = \\sum_x P(x) \\cdot (-\\log P(x)) = -\\sum_x P(x) \\log P(x)$\n",
    "- Cross Entropy : 모델 예측 기준으로 봤을 때, 실제 정답에 필요한 정보량\n",
    "    - 정답 분포 $P(x)$ 를 기준으로 사건별 예측한 정보량 $-\\log Q(x)$ 를 평균낸 것\n",
    "    - 정답 분포 $P$, 모델 예측 분포 $Q$일 때, $H(P, Q) = -\\sum_x P(x) \\log Q(x)$\n",
    "    - 의미 : 모델이 예측한 분포 $Q$를 기준으로, 정답 $P$를 설명하려면 **얼마나 많은 정보(코스트)가 필요한가?** -> \"LOSS\"\n",
    "- KL Divergence : 예측한 확률 분포가 정답 분포에서 얼마나 벗어났는지 (=정보 낭비량)\n",
    "    - $D_{KL}(P \\| Q)$ = $H(P, Q) - H(P)$ = $\\sum_x P(x) \\log \\frac{P(x)}{Q(x)}$\n",
    "    - 예측이 완벽하면 $Q = P$ 이므로 $D_{KL} = 0$\n",
    "    - 분포를 맞추는 문제, 예: VAE에서 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112abf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.17000000178813934\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "y_pred = torch.tensor([2.5, 0.0, 2.1])\n",
    "y_true = torch.tensor([3.0, -0.5, 2.0])\n",
    "\n",
    "loss_fn = nn.MSELoss()  # nn.L1Loss() (MAE), nn.BCELoss()\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "print(\"MSE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfcc9f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 0.4170299470424652\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "labels = torch.tensor([0])  # 정답 클래스 인덱스 -> 다중 클래스 분류\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(logits, labels)  # CrossEntropyLoss 내부에서 Softmax & log 자동 계산 \n",
    "print(\"Cross Entropy Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be13b0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence: 0.2554128170013428\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "P = torch.tensor([0.5, 0.5])  # 정답 분포\n",
    "Q = torch.tensor([0.9, 0.1])  # 예측 분포\n",
    "\n",
    "log_Q = Q.log()\n",
    "kl = F.kl_div(log_Q, P, reduction='batchmean')\n",
    "print(\"KL Divergence:\", kl.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
