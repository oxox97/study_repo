{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915cf76c",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88501390",
   "metadata": {},
   "source": [
    "(예제) XOR 문제 딥러닝 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876e5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15eb1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. XOR 데이터\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb19fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 모델 정의\n",
    "torch.manual_seed(530)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),    # 은닉층 : 입력 2 -> 출력 2 랜덤 초기화\n",
    "    nn.ReLU(),          # Relu 활성화 함수\n",
    "    nn.Linear(2, 1),    # 출력층(마지막) : 입력 2 -> 출력 1 랜덤 초기화\n",
    "    nn.Sigmoid()        # Sigmoid 활성화 함수 (확률처럼)\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCELoss()  # # Binary Cross-Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69612c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7088\n",
      "Epoch 1, Loss: 0.7058\n",
      "Epoch 10000, Loss: 0.0017\n",
      "Epoch 20000, Loss: 0.0008\n",
      "Epoch 30000, Loss: 0.0005\n",
      "Epoch 40000, Loss: 0.0004\n",
      "Epoch 50000, Loss: 0.0003\n",
      "Epoch 60000, Loss: 0.0002\n",
      "Epoch 70000, Loss: 0.0002\n",
      "Epoch 80000, Loss: 0.0002\n",
      "Epoch 90000, Loss: 0.0002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Hidden_W</th>\n",
       "      <th>Hidden_b</th>\n",
       "      <th>Output_W</th>\n",
       "      <th>Output_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.399, -0.457], [0.606, 0.699]]</td>\n",
       "      <td>[0.655, -0.051]</td>\n",
       "      <td>[[-0.647, 0.661]]</td>\n",
       "      <td>[-0.176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.407, -0.465], [0.603, 0.696]]</td>\n",
       "      <td>[0.645, -0.046]</td>\n",
       "      <td>[[-0.647, 0.655]]</td>\n",
       "      <td>[-0.178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>[[-2.779, -2.779], [2.779, 2.779]]</td>\n",
       "      <td>[2.779, -2.779]</td>\n",
       "      <td>[[-4.763, -4.764]]</td>\n",
       "      <td>[5.855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>[[-2.942, -2.942], [2.941, 2.941]]</td>\n",
       "      <td>[2.942, -2.941]</td>\n",
       "      <td>[[-5.047, -5.048]]</td>\n",
       "      <td>[6.613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>[[-3.03, -3.03], [3.03, 3.03]]</td>\n",
       "      <td>[3.03, -3.03]</td>\n",
       "      <td>[[-5.202, -5.203]]</td>\n",
       "      <td>[7.046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40000</td>\n",
       "      <td>[[-3.091, -3.091], [3.09, 3.09]]</td>\n",
       "      <td>[3.091, -3.09]</td>\n",
       "      <td>[[-5.307, -5.308]]</td>\n",
       "      <td>[7.349]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>[[-3.136, -3.136], [3.136, 3.136]]</td>\n",
       "      <td>[3.136, -3.136]</td>\n",
       "      <td>[[-5.387, -5.388]]</td>\n",
       "      <td>[7.583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60000</td>\n",
       "      <td>[[-3.173, -3.173], [3.172, 3.172]]</td>\n",
       "      <td>[3.173, -3.173]</td>\n",
       "      <td>[[-5.451, -5.452]]</td>\n",
       "      <td>[7.774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70000</td>\n",
       "      <td>[[-3.204, -3.204], [3.203, 3.203]]</td>\n",
       "      <td>[3.203, -3.203]</td>\n",
       "      <td>[[-5.504, -5.505]]</td>\n",
       "      <td>[7.934]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80000</td>\n",
       "      <td>[[-3.23, -3.23], [3.229, 3.229]]</td>\n",
       "      <td>[3.23, -3.229]</td>\n",
       "      <td>[[-5.55, -5.551]]</td>\n",
       "      <td>[8.073]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90000</td>\n",
       "      <td>[[-3.252, -3.252], [3.252, 3.252]]</td>\n",
       "      <td>[3.252, -3.252]</td>\n",
       "      <td>[[-5.59, -5.591]]</td>\n",
       "      <td>[8.194]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch                            Hidden_W         Hidden_b  \\\n",
       "0       0  [[-0.399, -0.457], [0.606, 0.699]]  [0.655, -0.051]   \n",
       "1       1  [[-0.407, -0.465], [0.603, 0.696]]  [0.645, -0.046]   \n",
       "2   10000  [[-2.779, -2.779], [2.779, 2.779]]  [2.779, -2.779]   \n",
       "3   20000  [[-2.942, -2.942], [2.941, 2.941]]  [2.942, -2.941]   \n",
       "4   30000      [[-3.03, -3.03], [3.03, 3.03]]    [3.03, -3.03]   \n",
       "5   40000    [[-3.091, -3.091], [3.09, 3.09]]   [3.091, -3.09]   \n",
       "6   50000  [[-3.136, -3.136], [3.136, 3.136]]  [3.136, -3.136]   \n",
       "7   60000  [[-3.173, -3.173], [3.172, 3.172]]  [3.173, -3.173]   \n",
       "8   70000  [[-3.204, -3.204], [3.203, 3.203]]  [3.203, -3.203]   \n",
       "9   80000    [[-3.23, -3.23], [3.229, 3.229]]   [3.23, -3.229]   \n",
       "10  90000  [[-3.252, -3.252], [3.252, 3.252]]  [3.252, -3.252]   \n",
       "\n",
       "              Output_W  Output_b  \n",
       "0    [[-0.647, 0.661]]  [-0.176]  \n",
       "1    [[-0.647, 0.655]]  [-0.178]  \n",
       "2   [[-4.763, -4.764]]   [5.855]  \n",
       "3   [[-5.047, -5.048]]   [6.613]  \n",
       "4   [[-5.202, -5.203]]   [7.046]  \n",
       "5   [[-5.307, -5.308]]   [7.349]  \n",
       "6   [[-5.387, -5.388]]   [7.583]  \n",
       "7   [[-5.451, -5.452]]   [7.774]  \n",
       "8   [[-5.504, -5.505]]   [7.934]  \n",
       "9    [[-5.55, -5.551]]   [8.073]  \n",
       "10   [[-5.59, -5.591]]   [8.194]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 학습\n",
    "records = []\n",
    "\n",
    "for epoch in range(100000):\n",
    "    output = model(X)           # 예측값 계산\n",
    "    loss = loss_fn(output, Y)   # 손실 계산\n",
    "\n",
    "    optimizer.zero_grad()       # 기울기 초기화\n",
    "    loss.backward()             # 역전파\n",
    "    optimizer.step()            # 파라미터 업데이트\n",
    "\n",
    "    if epoch % 10000 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "        records.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"hidden_weight\": model[0].weight.detach().numpy().copy(),\n",
    "            \"hidden_bias\": model[0].bias.detach().numpy().copy(),\n",
    "            \"output_weight\": model[2].weight.detach().numpy().copy(),\n",
    "            \"output_bias\": model[2].bias.detach().numpy().copy(),\n",
    "        })\n",
    "\n",
    "df_records = pd.DataFrame([\n",
    "    {\n",
    "        \"Epoch\": r[\"epoch\"],\n",
    "        \"Hidden_W\": r[\"hidden_weight\"].round(3),\n",
    "        \"Hidden_b\": r[\"hidden_bias\"].round(3),\n",
    "        \"Output_W\": r[\"output_weight\"].round(3),\n",
    "        \"Output_b\": r[\"output_bias\"].round(3),\n",
    "    }\n",
    "    for r in records\n",
    "])\n",
    "\n",
    "df_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f839ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "예측 결과:\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# 4. 결과 확인\n",
    "with torch.no_grad():\n",
    "    output = model(X)\n",
    "    predicted = torch.round(output)  # 0.5 기준 반올림 (이진 분류)\n",
    "    print(\"\\n예측 결과:\")\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9743c51",
   "metadata": {},
   "source": [
    "### XOR 모델 학습 과정 정리 : Epoch 0 → 1\n",
    "\n",
    "> ### 초기 파라미터 (Epoch 0)\n",
    "- layer1 : 은닉층\n",
    "- layer2 (마지막) : 출력층\n",
    "\n",
    "```\n",
    "W1 = [[-0.399, -0.457],\n",
    "      [ 0.606,  0.699]]\n",
    "b1 = [0.655, -0.051]\n",
    "W2 = [[-0.647, 0.661]]\n",
    "b2 = [-0.176]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> ### 순전파 (Forward)\n",
    "\n",
    "**1. 입력 $x$ (4개 샘플, 4 by 2)**\n",
    "\n",
    "$$\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**2. 은닉층 선형합: $z_1 = x W_1^{T} + b_1$** <br>\n",
    "(참고, xW와 b가 차원이 안 맞지만 토치의 브로드캐스팅 통해 연산 가능)\n",
    "\n",
    "$$\n",
    "z_1 = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "-0.399 & 0.606 \\\\\n",
    "-0.457 & 0.699\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "0.655 & -0.051\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "※ $b_1$는 shape이 $(2,)$이지만 **브로드캐스팅**에 의해 각 샘플마다 더해짐\n",
    "\n",
    "$$\n",
    "z_1 =\n",
    "\\begin{bmatrix}\n",
    "0.655 & -0.051 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "-0.201 & 1.254\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**3. ReLU 적용: $h = ReLU(z_1)$**\n",
    "\n",
    "$$\n",
    "h =\n",
    "\\begin{bmatrix}\n",
    "0.655 & 0.000 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "0.000 & 1.254\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**4. 출력층 선형합: $z_2 = h W_2^{T} + b_2$**\n",
    "\n",
    "$$\n",
    "z_2 = \n",
    "\\begin{bmatrix}\n",
    "0.655 & 0.000 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "0.000 & 1.254\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "-0.647 \\\\\n",
    "0.661\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "-0.176\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.5998 \\\\\n",
    "0.1242 \\\\\n",
    "0.0252 \\\\\n",
    "0.6529\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**5. 출력값: $y_{pred} = sigmoid(z_2)$**\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{bmatrix}\n",
    "0.3544 \\\\\n",
    "0.5310 \\\\\n",
    "0.5063 \\\\\n",
    "0.6577\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**6. 정답 $y$**\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Binary Cross Entropy Loss**\n",
    "\n",
    "```\n",
    "Loss = 0.705775\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 2. 역전파 (Backward)\n",
    "- y와 y_hat이 같기를 궁극적으로 목표\n",
    "- gradient(미분)를 활용하여 w와 b 업데이트\n",
    "- gradient를 통해 ... (좀 더 수식적으로 이해 필요)\n",
    "\n",
    "\n",
    "**출력층 오차: dL/dz2 = (y_pred - y) / 4**\n",
    "\n",
    "```\n",
    "[[ 0.0886],\n",
    " [-0.1172],\n",
    " [-0.1234],\n",
    " [ 0.1644]]\n",
    "```\n",
    "\n",
    "**출력층 기울기**\n",
    "\n",
    "```\n",
    "dW2 = [[0.0032, 0.0617]]\n",
    "db2 = 0.0123\n",
    "```\n",
    "\n",
    "**은닉층 기울기**\n",
    "\n",
    "```\n",
    "dW1 = [[ 0.0200,  0.0190],\n",
    "       [ 0.0068,  0.0078]]\n",
    "db1 = [ 0.0246, -0.0126]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 3. 파라미터 업데이트 (lr = 0.1)\n",
    "\n",
    "```\n",
    "W1 = [[-0.401, -0.459],\n",
    "      [ 0.605,  0.698]]\n",
    "\n",
    "b1 = [0.653, -0.050]\n",
    "\n",
    "W2 = [[-0.647, 0.655]]\n",
    "b2 = [-0.177]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Epoch 1 결과 요약\n",
    "\n",
    "| 파라미터 | Epoch 0                        | Epoch 1                        |\n",
    "|----------|----------------------------------|----------------------------------|\n",
    "| W1       | [[-0.399, -0.457], [0.606, 0.699]] | [[-0.401, -0.459], [0.605, 0.698]] |\n",
    "| b1       | [0.655, -0.051]                   | [0.653, -0.050]                   |\n",
    "| W2       | [[-0.647, 0.661]]                 | [[-0.647, 0.655]]                 |\n",
    "| b2       | [-0.176]                          | [-0.177]                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfd98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
