{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915cf76c",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88501390",
   "metadata": {},
   "source": [
    "(ì˜ˆì œ) XOR ë¬¸ì œ ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876e5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15eb1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. XOR ë°ì´í„°\n",
    "X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float)\n",
    "Y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb19fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (3): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. ëª¨ë¸ ì •ì˜\n",
    "torch.manual_seed(530)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 2),    # ì€ë‹‰ì¸µ : ì…ë ¥ 2 -> ì¶œë ¥ 2 ëœë¤ ì´ˆê¸°í™”\n",
    "    nn.ReLU(),          # Relu í™œì„±í™” í•¨ìˆ˜\n",
    "    nn.Linear(2, 1),    # ì¶œë ¥ì¸µ(ë§ˆì§€ë§‰) : ì…ë ¥ 2 -> ì¶œë ¥ 1 ëœë¤ ì´ˆê¸°í™”\n",
    "    nn.Sigmoid()        # Sigmoid í™œì„±í™” í•¨ìˆ˜ (í™•ë¥ ì²˜ëŸ¼)\n",
    ")\n",
    "\n",
    "loss_fn = nn.BCELoss()  # # Binary Cross-Entropy Loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69612c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7088\n",
      "Epoch 1, Loss: 0.7058\n",
      "Epoch 10000, Loss: 0.0017\n",
      "Epoch 20000, Loss: 0.0008\n",
      "Epoch 30000, Loss: 0.0005\n",
      "Epoch 40000, Loss: 0.0004\n",
      "Epoch 50000, Loss: 0.0003\n",
      "Epoch 60000, Loss: 0.0002\n",
      "Epoch 70000, Loss: 0.0002\n",
      "Epoch 80000, Loss: 0.0002\n",
      "Epoch 90000, Loss: 0.0002\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Hidden_W</th>\n",
       "      <th>Hidden_b</th>\n",
       "      <th>Output_W</th>\n",
       "      <th>Output_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.399, -0.457], [0.606, 0.699]]</td>\n",
       "      <td>[0.655, -0.051]</td>\n",
       "      <td>[[-0.647, 0.661]]</td>\n",
       "      <td>[-0.176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.407, -0.465], [0.603, 0.696]]</td>\n",
       "      <td>[0.645, -0.046]</td>\n",
       "      <td>[[-0.647, 0.655]]</td>\n",
       "      <td>[-0.178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>[[-2.779, -2.779], [2.779, 2.779]]</td>\n",
       "      <td>[2.779, -2.779]</td>\n",
       "      <td>[[-4.763, -4.764]]</td>\n",
       "      <td>[5.855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20000</td>\n",
       "      <td>[[-2.942, -2.942], [2.941, 2.941]]</td>\n",
       "      <td>[2.942, -2.941]</td>\n",
       "      <td>[[-5.047, -5.048]]</td>\n",
       "      <td>[6.613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>[[-3.03, -3.03], [3.03, 3.03]]</td>\n",
       "      <td>[3.03, -3.03]</td>\n",
       "      <td>[[-5.202, -5.203]]</td>\n",
       "      <td>[7.046]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40000</td>\n",
       "      <td>[[-3.091, -3.091], [3.09, 3.09]]</td>\n",
       "      <td>[3.091, -3.09]</td>\n",
       "      <td>[[-5.307, -5.308]]</td>\n",
       "      <td>[7.349]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50000</td>\n",
       "      <td>[[-3.136, -3.136], [3.136, 3.136]]</td>\n",
       "      <td>[3.136, -3.136]</td>\n",
       "      <td>[[-5.387, -5.388]]</td>\n",
       "      <td>[7.583]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60000</td>\n",
       "      <td>[[-3.173, -3.173], [3.172, 3.172]]</td>\n",
       "      <td>[3.173, -3.173]</td>\n",
       "      <td>[[-5.451, -5.452]]</td>\n",
       "      <td>[7.774]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70000</td>\n",
       "      <td>[[-3.204, -3.204], [3.203, 3.203]]</td>\n",
       "      <td>[3.203, -3.203]</td>\n",
       "      <td>[[-5.504, -5.505]]</td>\n",
       "      <td>[7.934]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80000</td>\n",
       "      <td>[[-3.23, -3.23], [3.229, 3.229]]</td>\n",
       "      <td>[3.23, -3.229]</td>\n",
       "      <td>[[-5.55, -5.551]]</td>\n",
       "      <td>[8.073]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>90000</td>\n",
       "      <td>[[-3.252, -3.252], [3.252, 3.252]]</td>\n",
       "      <td>[3.252, -3.252]</td>\n",
       "      <td>[[-5.59, -5.591]]</td>\n",
       "      <td>[8.194]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch                            Hidden_W         Hidden_b  \\\n",
       "0       0  [[-0.399, -0.457], [0.606, 0.699]]  [0.655, -0.051]   \n",
       "1       1  [[-0.407, -0.465], [0.603, 0.696]]  [0.645, -0.046]   \n",
       "2   10000  [[-2.779, -2.779], [2.779, 2.779]]  [2.779, -2.779]   \n",
       "3   20000  [[-2.942, -2.942], [2.941, 2.941]]  [2.942, -2.941]   \n",
       "4   30000      [[-3.03, -3.03], [3.03, 3.03]]    [3.03, -3.03]   \n",
       "5   40000    [[-3.091, -3.091], [3.09, 3.09]]   [3.091, -3.09]   \n",
       "6   50000  [[-3.136, -3.136], [3.136, 3.136]]  [3.136, -3.136]   \n",
       "7   60000  [[-3.173, -3.173], [3.172, 3.172]]  [3.173, -3.173]   \n",
       "8   70000  [[-3.204, -3.204], [3.203, 3.203]]  [3.203, -3.203]   \n",
       "9   80000    [[-3.23, -3.23], [3.229, 3.229]]   [3.23, -3.229]   \n",
       "10  90000  [[-3.252, -3.252], [3.252, 3.252]]  [3.252, -3.252]   \n",
       "\n",
       "              Output_W  Output_b  \n",
       "0    [[-0.647, 0.661]]  [-0.176]  \n",
       "1    [[-0.647, 0.655]]  [-0.178]  \n",
       "2   [[-4.763, -4.764]]   [5.855]  \n",
       "3   [[-5.047, -5.048]]   [6.613]  \n",
       "4   [[-5.202, -5.203]]   [7.046]  \n",
       "5   [[-5.307, -5.308]]   [7.349]  \n",
       "6   [[-5.387, -5.388]]   [7.583]  \n",
       "7   [[-5.451, -5.452]]   [7.774]  \n",
       "8   [[-5.504, -5.505]]   [7.934]  \n",
       "9    [[-5.55, -5.551]]   [8.073]  \n",
       "10   [[-5.59, -5.591]]   [8.194]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. í•™ìŠµ\n",
    "records = []\n",
    "\n",
    "for epoch in range(100000):\n",
    "    output = model(X)           # ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
    "    loss = loss_fn(output, Y)   # ì†ì‹¤ ê³„ì‚°\n",
    "\n",
    "    optimizer.zero_grad()       # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "    loss.backward()             # ì—­ì „íŒŒ\n",
    "    optimizer.step()            # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸\n",
    "\n",
    "    if epoch % 10000 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "        records.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"hidden_weight\": model[0].weight.detach().numpy().copy(),\n",
    "            \"hidden_bias\": model[0].bias.detach().numpy().copy(),\n",
    "            \"output_weight\": model[2].weight.detach().numpy().copy(),\n",
    "            \"output_bias\": model[2].bias.detach().numpy().copy(),\n",
    "        })\n",
    "\n",
    "df_records = pd.DataFrame([\n",
    "    {\n",
    "        \"Epoch\": r[\"epoch\"],\n",
    "        \"Hidden_W\": r[\"hidden_weight\"].round(3),\n",
    "        \"Hidden_b\": r[\"hidden_bias\"].round(3),\n",
    "        \"Output_W\": r[\"output_weight\"].round(3),\n",
    "        \"Output_b\": r[\"output_bias\"].round(3),\n",
    "    }\n",
    "    for r in records\n",
    "])\n",
    "\n",
    "df_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f839ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì˜ˆì¸¡ ê²°ê³¼:\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# 4. ê²°ê³¼ í™•ì¸\n",
    "with torch.no_grad():\n",
    "    output = model(X)\n",
    "    predicted = torch.round(output)  # 0.5 ê¸°ì¤€ ë°˜ì˜¬ë¦¼ (ì´ì§„ ë¶„ë¥˜)\n",
    "    print(\"\\nì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9743c51",
   "metadata": {},
   "source": [
    "### XOR ëª¨ë¸ í•™ìŠµ ê³¼ì • ì •ë¦¬ : Epoch 0 â†’ 1\n",
    "\n",
    "> ### ì´ˆê¸° íŒŒë¼ë¯¸í„° (Epoch 0)\n",
    "- layer1 : ì€ë‹‰ì¸µ\n",
    "- layer2 (ë§ˆì§€ë§‰) : ì¶œë ¥ì¸µ\n",
    "\n",
    "```\n",
    "W1 = [[-0.399, -0.457],\n",
    "      [ 0.606,  0.699]]\n",
    "b1 = [0.655, -0.051]\n",
    "W2 = [[-0.647, 0.661]]\n",
    "b2 = [-0.176]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "> ### ìˆœì „íŒŒ (Forward)\n",
    "\n",
    "**1. ì…ë ¥ $x$ (4ê°œ ìƒ˜í”Œ, 4 by 2)**\n",
    "\n",
    "$$\n",
    "x =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**2. ì€ë‹‰ì¸µ ì„ í˜•í•©: $z_1 = x W_1^{T} + b_1$** <br>\n",
    "(ì°¸ê³ , xWì™€ bê°€ ì°¨ì›ì´ ì•ˆ ë§ì§€ë§Œ í† ì¹˜ì˜ ë¸Œë¡œë“œìºìŠ¤íŒ… í†µí•´ ì—°ì‚° ê°€ëŠ¥)\n",
    "\n",
    "$$\n",
    "z_1 = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "-0.399 & 0.606 \\\\\n",
    "-0.457 & 0.699\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "0.655 & -0.051\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "â€» $b_1$ëŠ” shapeì´ $(2,)$ì´ì§€ë§Œ **ë¸Œë¡œë“œìºìŠ¤íŒ…**ì— ì˜í•´ ê° ìƒ˜í”Œë§ˆë‹¤ ë”í•´ì§\n",
    "\n",
    "$$\n",
    "z_1 =\n",
    "\\begin{bmatrix}\n",
    "0.655 & -0.051 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "-0.201 & 1.254\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**3. ReLU ì ìš©: $h = ReLU(z_1)$**\n",
    "\n",
    "$$\n",
    "h =\n",
    "\\begin{bmatrix}\n",
    "0.655 & 0.000 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "0.000 & 1.254\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**4. ì¶œë ¥ì¸µ ì„ í˜•í•©: $z_2 = h W_2^{T} + b_2$**\n",
    "\n",
    "$$\n",
    "z_2 = \n",
    "\\begin{bmatrix}\n",
    "0.655 & 0.000 \\\\\n",
    "0.198 & 0.648 \\\\\n",
    "0.256 & 0.555 \\\\\n",
    "0.000 & 1.254\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "-0.647 \\\\\n",
    "0.661\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "-0.176\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "-0.5998 \\\\\n",
    "0.1242 \\\\\n",
    "0.0252 \\\\\n",
    "0.6529\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**5. ì¶œë ¥ê°’: $y_{pred} = sigmoid(z_2)$**\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{bmatrix}\n",
    "0.3544 \\\\\n",
    "0.5310 \\\\\n",
    "0.5063 \\\\\n",
    "0.6577\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "**6. ì •ë‹µ $y$**\n",
    "\n",
    "$$\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Binary Cross Entropy Loss**\n",
    "\n",
    "```\n",
    "Loss = 0.705775\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” 2. ì—­ì „íŒŒ (Backward)\n",
    "- yì™€ y_hatì´ ê°™ê¸°ë¥¼ ê¶ê·¹ì ìœ¼ë¡œ ëª©í‘œ\n",
    "- gradient(ë¯¸ë¶„)ë¥¼ í™œìš©í•˜ì—¬ wì™€ b ì—…ë°ì´íŠ¸\n",
    "- gradientë¥¼ í†µí•´ ... (ì¢€ ë” ìˆ˜ì‹ì ìœ¼ë¡œ ì´í•´ í•„ìš”)\n",
    "\n",
    "\n",
    "**ì¶œë ¥ì¸µ ì˜¤ì°¨: dL/dz2 = (y_pred - y) / 4**\n",
    "\n",
    "```\n",
    "[[ 0.0886],\n",
    " [-0.1172],\n",
    " [-0.1234],\n",
    " [ 0.1644]]\n",
    "```\n",
    "\n",
    "**ì¶œë ¥ì¸µ ê¸°ìš¸ê¸°**\n",
    "\n",
    "```\n",
    "dW2 = [[0.0032, 0.0617]]\n",
    "db2 = 0.0123\n",
    "```\n",
    "\n",
    "**ì€ë‹‰ì¸µ ê¸°ìš¸ê¸°**\n",
    "\n",
    "```\n",
    "dW1 = [[ 0.0200,  0.0190],\n",
    "       [ 0.0068,  0.0078]]\n",
    "db1 = [ 0.0246, -0.0126]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ 3. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ (lr = 0.1)\n",
    "\n",
    "```\n",
    "W1 = [[-0.401, -0.459],\n",
    "      [ 0.605,  0.698]]\n",
    "\n",
    "b1 = [0.653, -0.050]\n",
    "\n",
    "W2 = [[-0.647, 0.655]]\n",
    "b2 = [-0.177]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Epoch 1 ê²°ê³¼ ìš”ì•½\n",
    "\n",
    "| íŒŒë¼ë¯¸í„° | Epoch 0                        | Epoch 1                        |\n",
    "|----------|----------------------------------|----------------------------------|\n",
    "| W1       | [[-0.399, -0.457], [0.606, 0.699]] | [[-0.401, -0.459], [0.605, 0.698]] |\n",
    "| b1       | [0.655, -0.051]                   | [0.653, -0.050]                   |\n",
    "| W2       | [[-0.647, 0.661]]                 | [[-0.647, 0.655]]                 |\n",
    "| b2       | [-0.176]                          | [-0.177]                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfd98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
