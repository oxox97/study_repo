{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 장단점\n",
    "- 장점\n",
    "    - 문맥 파악 용이\n",
    "    - 병렬 연산 가능 : RNN(순환 신경망)같은 모델은 문장(시퀀스)을 한 단어씩 순서대로 처리하는 반면, 어텐션은 모든 단어가 다른 단어와 어떤 관련(가중치)이 있는지 동시에 계산할 수 있어 병렬 연산 가능 -> 빠른 연산 속도\n",
    "    - 모듈화 및 확장성 : 기존 CNN이나 RNN 모델에 \"Attention Block\"을 추가하여 성능을 높일수도 있고, Self-Attention, Cross-Attention, Multi-Head Attention 등 변형 및 확장 가능\n",
    "    - 직관적 해석 가능 : 출력된 attention 가중치로 어떤 부분에 모델이 집중했는지 시각화 가능 (Explainability)\n",
    "- 단점\n",
    "    - 고비용 연산 : 모든 쌍에 대한 유사도(가중치) 계산 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 개요\n",
    "- 정의 : 어텐션은 입력 데이터를 처리할 때, 딥러닝 모델이 **특정 부분에 가중치를 더 많이 두어 집중**할 수 있게 하는 알고리즘(매커니즘)\n",
    "- 등장 배경 : 자연어 처리나 컴퓨터 비전에서 모든 입력 요소에 동일한 비중을 두는 방식의 한계 극복, 예를 들어 문장 내에서 어떤 단어가 더 중요한지 스스로 학습하고 그 중요한 단어에 더 비중을 두어 계산하게 만들기 위함\n",
    "- Transformer는 딥러닝에서 문장(시퀀스) 처리를 위해 고안된 모델 구조이며, 인코더-디코더 구조를 사용하고 내부에 여러 개의 Attention 기법을 조합하여 작동\n",
    "    - Attention 기법은 다른 신경망(CNN, RNN 등)에서도 모듈로 붙여쓰고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 활용 예시\n",
    "- 자연어 처리(NLP)\n",
    "    - 기계 번역(Transformer 기반), 질의응답 시스템, 텍스트 분류, 요약 등\n",
    "- 컴퓨터 비전\n",
    "    - 이미지 분류나 물체 디텍션에서 이미지의 특정 영역에 집중하여 검출하는 Vision Transformer(ViT)\n",
    "- 음성 처리\n",
    "    - 음성 인식(STT), 음성 합성(TTS) 등에서 Self-Attention 활용\n",
    "- 추천 시스템\n",
    "    - 사용자-아이템 시퀀스에서 주목할 아이템에 가중치를 두어 추천 정확도 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. 참고\n",
    "- 인코더(Encoder) : 입력을 이해하고, 정리하여 요약 정보(벡터 표현)로 만들어주는 부분\n",
    "    - 예) 번역할 때 한국어 문장을 분석하여 \"무엇을 말하고 있는지 알아내는 과정\"\n",
    "- 디코더(Decoder) : 인코더가 만든 요약 정보(벡터)를 바탕으로 출력을 생성하는 부분\n",
    "    - 예) 번역 모델에서 한국어 문장 요약 정보를 토대로 영어 문장 \"단어 하나씩 만들어내는 과정\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션 -> 트랜스포머로 공부 항목 변경?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자연어 (NLP) 모델  순서대로 가자 RNN LSTM Seq2Seq Transformer 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
