{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "### 1. 단어 수 기반 벡터화\n",
    "- Bag of Words (BoW) : 각 단어의 등장 횟수를 세서 벡터로 표현\n",
    "- TF-IDF : 흔하게 등장하는 단어에는 낮은 가중치를, 특정 문서에만 자주 등장하는 단어엔 높은 가중치\n",
    "    - 계산식\n",
    "    $$\n",
    "   \\text{TF}(t, d) = \\frac{\\text{단어 } t \\text{가 문서 } d \\text{에 등장한 횟수}}{\\text{문서 } d \\text{의 총 단어 수}}\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   \\text{IDF}(t, D) = \\log \\left( \\frac{|D|}{|\\{d \\in D : t \\in d\\}|} \\right)\n",
    "   $$\n",
    "   \n",
    "    - \\( |D| \\): 전체 문서 수\n",
    "    - \\( \\{d \\in D : t \\in d\\} \\): 단어 \\( t \\)가 포함된 문서의 집합\n",
    "\n",
    "\n",
    "\n",
    "### 2. 단어 임베딩 기반 벡터화\n",
    "\n",
    "- 단어와 주변 단어(context) 사이의 관계를 예측하여 의미를 반영한 고차원 실수 벡터 학습\n",
    "    - e.g. `king - man + woman ≈ queen`\n",
    "- 종류\n",
    "    - Word2Vec : 단어의 의미를 벡터 공간 상에 표현하는 임베딩 방법으로, 의미가 비슷한 단어는 벡터 거리 가깝게 학습됨\n",
    "        - 의미가 비슷한 단어는 어떻게 정의? 비슷한 문맥(context)에서 사용됨\n",
    "        - 종류\n",
    "            - CBOW (Continuous Bag of Words) : 주변 단어들을 보고 중심 단어를 예측 (일반적인 단어에 유리)\n",
    "            - Skip-gram : 중심 단어를 보고 주변 단어를 예측 (희귀 단어에 유리)\n",
    "        - 사실상 간단한 신경망 (1 hidden layer)\n",
    "            - 입력층 : One-hot 벡터 (어휘 수 V 차원)\n",
    "            - 은닉층 : Embedding matrix W (V X N) -> **단어를 N차원 임베딩으로 변환**\n",
    "            - 출력층 : Softmax 확률 분포 -> 예측 결과\n",
    "    - GloVe\n",
    "    - FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"나는 콜드플레이 노래를 좋아한다\",\n",
    "    \"디즈니 영화를 보고있다\",\n",
    "    \"좋은 날씨에 종종 테니스를 친다\",\n",
    "    \"좋은 날씨에 잔다\",\n",
    "    \"영화가 좋은 나는 영화를 본다\",\n",
    "    \"콜드플레이는 영화를 찍은 적이 있나?\",\n",
    "    \"날씨가 좋아야 밖에 나간다\",\n",
    "    \"테니스 만화는 테니스를 내용이다 그것이 테니스니까\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['나', '는', '콜드플레이', '노래', '를', '좋아하', 'ᆫ다'],\n",
       " ['디즈니', '영화', '를', '보', '고', '있', '다'],\n",
       " ['좋', '은', '날씨', '에', '종종', '테니스', '를', '치', 'ᆫ다'],\n",
       " ['좋', '은', '날씨', '에', '자', 'ᆫ다'],\n",
       " ['영화', '가', '좋', '은', '나', '는', '영화', '를', '보', 'ᆫ다'],\n",
       " ['콜드플레이', '는', '영화', '를', '찍', '은', '적', '이', '있', '나', '?'],\n",
       " ['날씨', '가', '좋', '어야', '밖', '에', '나가', 'ᆫ다'],\n",
       " ['테니스', '만화', '는', '테니스', '를', '내용', '이', '다', '그것', '이', '테니스', '이', '니까']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "\n",
    "kiwi = Kiwi()  # Korean Intelligent Word Identifier\n",
    "docs_kiwi = []\n",
    "\n",
    "for d in docs:\n",
    "    result = kiwi.analyze(d)\n",
    "    tokens = [token.form for token in result[0][0]]  # tag : 품사\n",
    "    \n",
    "    docs_kiwi.append(tokens)\n",
    "\n",
    "docs_kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW feature names: ['ᆫ다' '그것' '나가' '날씨' '내용' '노래' '니까' '디즈니' '만화' '어야' '영화' '종종' '좋아하'\n",
      " '콜드플레이' '테니스']\n",
      "Bow vector:\n",
      " [[1 0 0 0 0 1 0 0 0 0 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n",
      " [1 0 1 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 1 0 1 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# 1. BoW\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow = bow_vectorizer.fit_transform([\" \".join(tokens) for tokens in docs_kiwi])\n",
    "\n",
    "print(\"BoW feature names:\", bow_vectorizer.get_feature_names_out())  # 사전 순 단어 정렬\n",
    "print(\"Bow vector:\\n\", bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_IDF feature names: ['ᆫ다' '그것' '나가' '날씨' '내용' '노래' '니까' '디즈니' '만화' '어야' '영화' '종종' '좋아하'\n",
      " '콜드플레이' '테니스']\n",
      "TF-IDF vector:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ᆫ다</th>\n",
       "      <th>그것</th>\n",
       "      <th>나가</th>\n",
       "      <th>날씨</th>\n",
       "      <th>내용</th>\n",
       "      <th>노래</th>\n",
       "      <th>니까</th>\n",
       "      <th>디즈니</th>\n",
       "      <th>만화</th>\n",
       "      <th>어야</th>\n",
       "      <th>영화</th>\n",
       "      <th>종종</th>\n",
       "      <th>좋아하</th>\n",
       "      <th>콜드플레이</th>\n",
       "      <th>테니스</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575683</td>\n",
       "      <td>0.482467</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.352144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.627406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.613115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.361767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.932268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.757092</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593597</td>\n",
       "      <td>0.429285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.311266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.782595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ᆫ다        그것        나가        날씨        내용        노래        니까  \\\n",
       "0  0.323114  0.000000  0.000000  0.000000  0.000000  0.575683  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.352144  0.000000  0.000000  0.453735  0.000000  0.000000  0.000000   \n",
       "3  0.613115  0.000000  0.000000  0.789994  0.000000  0.000000  0.000000   \n",
       "4  0.361767  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.333168  0.000000  0.593597  0.429285  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.311266  0.000000  0.000000  0.311266  0.000000  0.311266   \n",
       "\n",
       "        디즈니        만화        어야        영화        종종       좋아하     콜드플레이  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.575683  0.482467   \n",
       "1  0.810306  0.000000  0.000000  0.586007  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.627406  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.932268  0.000000  0.000000  0.000000   \n",
       "5  0.000000  0.000000  0.000000  0.653308  0.000000  0.000000  0.757092   \n",
       "6  0.000000  0.000000  0.593597  0.000000  0.000000  0.000000  0.000000   \n",
       "7  0.000000  0.311266  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        테니스  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.525815  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.000000  \n",
       "7  0.782595  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform([\" \".join(tokens) for tokens in docs_kiwi])\n",
    "\n",
    "print(\"TF_IDF feature names:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF vector:\\n\")\n",
    "display(pd.DataFrame(tfidf.toarray(), columns=bow_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"data/ratings.txt\")\n",
    "train_data  = pd.read_table('data/ratings.txt')\n",
    "train_data  # label : 긍정(1), 부정(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
